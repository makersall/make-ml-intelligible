I"⁄<h2 id="jennifer-qs">Jennifer Qs</h2>
<ul>
  <li>Building data sheets into workflow tools‚Äî eg, Designer‚Äî so UX makes easier to add into flow in a way that allows for flexibility of diff workflows</li>
  <li>Making UX designers a key part of team just as they are w web development?</li>
  <li>Considering guerilla usability?  UX of tool builders</li>
  <li>Thought at all about trying out community-centered UX approach?</li>
</ul>

<h1 id="jennifer-talk">Jennifer talk</h1>

<h2 id="what-to-call-it">What to Call It</h2>
<ul>
  <li>EU likes Explainability</li>
  <li>She prefers Intelligibility</li>
</ul>

<h2 id="some-basic-approaches-to-intelligibility">Some basic approaches to intelligibility</h2>
<ul>
  <li>Dan Goldstein: simple point systems</li>
  <li>Rich Caruana: GAMs,  additive structure, so can visualize impact</li>
  <li>Approach 2: post hoc explaination
    <ul>
      <li>LIME or SHAP</li>
      <li>Can play w them on InterpretML - Azure ML also uses it</li>
    </ul>
  </li>
</ul>

<h2 id="issues">Issues</h2>
<ul>
  <li>Difficulty: different stakeholders / users have different intelligibility needs‚Äî eg, CEO vs regulator vs debugging it</li>
  <li>
    <p>One wide open direction: understanding needs of stakeholders</p>
  </li>
  <li>Not just intelligibility at creation of model but the whole shebang ‚Äì e.g., performance metrics intelligibility</li>
  <li>
    <p>Human centered agenda for intelligible ML(  Book chapter!)</p>
  </li>
  <li>Me: Intelligibility for what?
    <ul>
      <li>‚ÄúAs a user, I understand it so I can ___‚Äù</li>
    </ul>
  </li>
</ul>

<h2 id="study">Study</h2>
<ul>
  <li>Few people could describe what the intelligibility visualization meant</li>
  <li>In fact, intelligibility data viz made people more confident when they shouldn‚Äôt be</li>
  <li>Folks found GAMs easier to understand</li>
  <li>But no diff for, should we deploy?</li>
  <li>One conclusion: we need tools to encourage deep learning and discourage snap judgments</li>
</ul>

:ET