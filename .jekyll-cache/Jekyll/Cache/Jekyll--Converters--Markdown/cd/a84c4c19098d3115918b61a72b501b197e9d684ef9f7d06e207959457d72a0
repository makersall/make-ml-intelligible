I"ÿ<h2 id="my-thoughts">My Thoughts</h2>
<ul>
  <li><a href="../anders-dump/">My thoughts</a>, to be sorted out</li>
</ul>

<h2 id="microsoft">Microsoft</h2>
<ul>
  <li><a href="http://www.jennwv.com">Jennifer Wortman Vaughan</a> and Hanna Wallach, <a href="http://www.jennwv.com/papers/intel-chapter.pdf">A Human-Centered Agenda for Intelligible Machine Learning</a>
    <ul>
      <li>Also papers on how data scientists can <a href="http://www.jennwv.com/papers/interp-ds.pdf?mkt_tok=eyJpIjoiTjJFd1l6VmtZemczWlRRNSIsInQiOiJvZXNMR3F0MFM4S2xIdW9KVk1KQnowVENpMkV2NmxleXBsZURLZnNweFVwXC8yalFVUE52YlN5TVNFd2k0dUg1RzE1dXZpUFwvUlgzOXJPYmRjXC9qeHhzQnZpaGVLNlJ5T3o2RnplK1ZLbk1jN2pFVXVEaHVjQkp3QUUxb1c4cWtmaCJ9">misinterpret interpretability tools</a>, <a href="https://arxiv.org/pdf/1802.07810.pdf">measuring model interpretabiliy</a>, impact of <a href="http://www.jennwv.com/papers/accuracy-trust.pdf?mkt_tok=eyJpIjoiTjJFd1l6VmtZemczWlRRNSIsInQiOiJvZXNMR3F0MFM4S2xIdW9KVk1KQnowVENpMkV2NmxleXBsZURLZnNweFVwXC8yalFVUE52YlN5TVNFd2k0dUg1RzE1dXZpUFwvUlgzOXJPYmRjXC9qeHhzQnZpaGVLNlJ5T3o2RnplK1ZLbk1jN2pFVXVEaHVjQkp3QUUxb1c4cWtmaCJ9">accuracy on trust</a>,</li>
    </ul>
  </li>
  <li>possible interview questions for Jennifer are in the  <a href="../jennifer/">notes dump</a></li>
  <li><a href="../jennifer/">Jennifer talk</a></li>
  <li><a href="https://www.microsoft.com/en-us/research/people/rcaruana/">Rich Caruana</a>: <a href="https://www.youtube.com/watch?v=TPY16CSIrwY">Friends Don‚Äôt Let Friends Deploy Black-Box Models</a></li>
  <li>Notes on <a href="../pages/dump/microsoft-azure.html">Microsoft Azure</a>
    <ul>
      <li>Chris Lauren, Principle Program Manager Lead (@clauren42), Azure Machine Learning Platform</li>
    </ul>
  </li>
  <li><a href="https://github.com/interpretml/interpret">InterpretML</a>: an open-source python package for training interpretable machine learning models and explaining blackbox systems.</li>
</ul>

<h2 id="google">Google</h2>
<ul>
  <li><a href="https://pair.withgoogle.com/">People and AI Guidebook</a>
    <ul>
      <li><a href="https://pair.withgoogle.com/chapter/mental-models/">People‚Äôs Mental Models</a></li>
      <li><a href="https://pair.withgoogle.com/chapter/explainability-trust/">Explainability</a> And Trust</li>
    </ul>
  </li>
  <li>Sara Hooker, Google Brain: <a href="https://www.sarahooker.me/research.html">research</a> w focus on vision, ML <a href="https://www.sarahooker.me/curriculum.html">curriculum</a> (beta, part of the nonprofit <a href="http://www.deltanalytics.org">Delta Analytics</a>)</li>
  <li>Google‚Äôs <a href="https://pair-code.github.io/what-if-tool/">What-If</a> Tool, For inspecting a machine learning model
    <ul>
      <li>Site has a bunch of links to articles, demos, etc.</li>
      <li>Medium article on <a href="https://towardsdatascience.com/using-what-if-tool-to-investigate-machine-learning-models-913c7d4118f">how to use the What-If tool</a></li>
    </ul>
  </li>
  <li><a href="https://research.google/teams/brain/pair/">People and AI Research</a> (PAIR)</li>
  <li><a href="https://ai.google/education/">Learn with Google AI</a></li>
</ul>

<h2 id="aiml-bias">AI/ML Bias</h2>
<ul>
  <li><a href="https://afog.berkeley.edu">Algorithmic Fairness and Opacity Working Group</a></li>
  <li><a href="https://ainowinstitute.org">AI Now Institute</a></li>
  <li><a href="https://www.fatml.org">Fairness, Accountability, and Transparency
in Machine Learning</a></li>
</ul>

<h2 id="other">Other</h2>
<ul>
  <li>DARPA‚Äôs <a href="https://www.darpa.mil/program/explainable-artificial-intelligence">Explainable AI </a>(XAI) program</li>
</ul>

<h2 id="key-papers">Key Papers</h2>
<ul>
  <li><a href="https://people.eng.unimelb.edu.au/tmiller/">Tim Miller</a>, Piers Howe, <a href="https://people.eng.unimelb.edu.au/lizs/">Liz Sonenberg</a>, ‚Äú<a href="https://arxiv.org/abs/1712.00547">Explainable AI: Beware of Inmates Running the Asylum, Or: How I Learnt to Stop Worrying and Love the Social and Behavioural Sciences</a>.‚Äù  From research out of University of Melbourne‚Äôs <a href="https://cis.unimelb.edu.au/agentlab/explainable-ai/">A.I. and Autonomy Lab</a></li>
</ul>

<h2 id="sample-data">Sample Data</h2>
<ul>
  <li><a href="https://archive.ics.uci.edu/ml/index.php">UCI‚Äôs ML Data Repository</a></li>
</ul>
:ET