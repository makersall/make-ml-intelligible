[interview](https://www.microsoft.com/en-us/research/blog/making-intelligence-intelligible-dr-rich-caruana/)
> Rich Caruana: So, back when I was a graduate student, my advisor, Tom Mitchell, who’s well-known in the machine learning community, asked me to train a neural net on a pneumonia data set that he was working with, with a number of other colleagues. So, I trained a neural net on this data, and guess I got lucky. It turned out the neural net I trained was the most accurate model anyone could train on this data set. And then there was a question, you know, would it actually be safe for us to go ahead and use this neural net on real patients? And I said, “You know, I don’t think we should use this neural net on real people. And that’s because it’s a black box. We don’t actually understand what it’s doing.” And what had me concerned was a friend who was at another university, who was training on the same data set, but he was using rule-based learning, he learned a rule one night, that if you have a history of asthma, it lowers your chance of dying from pneumonia. That is asthma seems to be protective, you know, for pneumonia. And he’s like, “Rich, what do you think that means?” And so, we took it to the next meeting. There were real MDs involved in this project. And the MDs said, “Wow, we consider asthma to be a serious risk factor for people who now have pneumonia, so we don’t want your model to predict that asthma’s good for you. That’s a bad thing.” But we can kind of see how that might be a real pattern in the data. You know, asthmatics are paying attention to how they’re breathing. They probably notice the symptoms of pneumonia earlier than most people would. You know, they have a healthcare professional who probably treats their asthma, so they’re already plugged into healthcare. So, they’re going to get an appointment, and they’re going to get earlier diagnosis that, in fact, what they have is not an asthma-related problem, but that they’ve got pneumonia. And because they’re considered high-risk patients, they’re actually going to get really high-quality, you know, aggressive treatment. They’re going to get it sooner than other people because they’re paying more attention. So, and it turns out if you’ve got an infection, there’s nothing better than getting, like, rapid diagnosis and rapid treatment. So, it turns out the asthmatics actually have almost half the chance of dying of the non-asthmatics. It’s not because the asthma is good for them. But it’s because they get to healthcare faster and they get to treatment faster. And the problem is that the rule-based system learned this rule that asthma is good for you. I assume a neural net that I trained on exactly the same data, learned the same pattern that asthma looks good for you. But if we’re going to use that model to go out and intervene in your healthcare and we deny the asthmatics the sort of rapid, high-quality care that made them low-risk, then we’ll actually be, possibly, harming asthmatics. And what I told them was, I said, my neural net probably has this asthma problem in it. That doesn’t worry me, because I can probably figure out how to make that problem go away. What really scares me is, what else did the neural net learn that’s similarly risky? But the rule-based system didn’t learn it, and therefore I don’t have a warning that I have this other problem in the neural net